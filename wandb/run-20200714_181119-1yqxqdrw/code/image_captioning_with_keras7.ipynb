{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import string\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "from numpy import array\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pickle import load, dump\n",
    "# from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications import ResNet152V2\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "# from keras.applications.inception_v3 import preprocess_input\n",
    "# from keras.applications.resnet_v2 import preprocess_input\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras import Input\n",
    "from keras.layers import Dropout, Dense, Embedding, LSTM, GaussianDropout, BatchNormalization\n",
    "from keras.layers.merge import add\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/vipul43/model8\" target=\"_blank\">https://app.wandb.ai/vipul43/model8</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/vipul43/model8/runs/1t2wp5uc\" target=\"_blank\">https://app.wandb.ai/vipul43/model8/runs/1t2wp5uc</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/vipul43/model8/runs/1t2wp5uc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL ONLY ONCE\n",
    "import wandb\n",
    "wandb.init(project=\"model8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACTING TEXT DATA AND PREPROCESSING\n",
    "#STEP: EXTRACTING DATA\n",
    "filepath = \"../../../Downloads/Flickr8k/Flickr8k_text/Flickr8k.token.txt\"\n",
    "file = open(filepath, 'r')\n",
    "content = file.read()\n",
    "file.close()\n",
    "lines = content.split('\\n')\n",
    "\n",
    "#STEP: SAVING DATA IN A DICTIONARY FOR TIME EFFICIENCY PURPOSES\n",
    "tokens_dic = {}\n",
    "for line in lines:\n",
    "    tokens = line.split()\n",
    "    image_ = tokens[0]\n",
    "    caption = ' '.join(tokens[1:])\n",
    "    image_title = image_.split('.')[0]\n",
    "    if(image_title not in tokens_dic.keys()):\n",
    "        tokens_dic[image_title] = [caption]\n",
    "    else:\n",
    "        tokens_dic[image_title].append(caption)\n",
    "\n",
    "\n",
    "#STEP: PREPROCESSING\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "for captions in tokens_dic.values():\n",
    "    for i in range(len(captions)):\n",
    "        caption = captions[i]\n",
    "        words = caption.split()\n",
    "        words = [word.lower() for word in words]\n",
    "        words = [word.translate(table) for word in words]\n",
    "        words = [word for word in words if len(word)>1]\n",
    "        words = [word for word in words if word.isalpha()]\n",
    "        captions[i] = ' '.join(words)\n",
    "        \n",
    "\n",
    "#LOADING TRAINING SET\n",
    "\n",
    "#STEP: EXTRACTING DATA\n",
    "filepath = \"../../../Downloads/Flickr8k/Flickr8k_text/Flickr_8k.trainImages.txt\"\n",
    "file = open(filepath, \"r\")\n",
    "content = file.read()\n",
    "file.close()\n",
    "lines = content.split('\\n')\n",
    "\n",
    "#STEP: SAVING DATA IN A LIST\n",
    "train = []\n",
    "for line in lines:\n",
    "    [image_title, stuff] =  line.split('.')\n",
    "    train.append(image_title)\n",
    "#NOTE: SIZE OF TRAIN LIST IS 6000\n",
    "\n",
    "#STEP: SAVING IMAGE-CAPTIONS IN TRAIN DATASET\n",
    "train_dataset = {}\n",
    "max_caption_length = 0\n",
    "for image_title, captions in tokens_dic.items():\n",
    "    if(image_title in train and (image_title not in train_dataset.keys())):\n",
    "        train_dataset[image_title] = list()\n",
    "        for caption in captions:\n",
    "            refined_caption = \"startseq \" + caption + \" endseq\"\n",
    "            train_dataset[image_title].append(refined_caption)\n",
    "            max_caption_length = max(max_caption_length, len(refined_caption.split()))\n",
    "#NOTE: SIZE OF TRAIN DATASET IS 6000\n",
    "\n",
    "\n",
    "#LOADING CROSS VALIDATION(OR DEVELOPMENT) SET\n",
    "\n",
    "#STEP: EXTRACTING DATA\n",
    "filepath = \"../../../Downloads/Flickr8k/Flickr8k_text/Flickr_8k.devImages.txt\"\n",
    "file = open(filepath, \"r\")\n",
    "content = file.read()\n",
    "file.close()\n",
    "lines = content.split('\\n')\n",
    "\n",
    "#STEP: SAVING DATA IN A LIST\n",
    "dev = []\n",
    "for line in lines:\n",
    "    [image_title, stuff] =  line.split('.')\n",
    "    dev.append(image_title)\n",
    "#NOTE: SIZE OF TEST LIST IS 1000\n",
    "\n",
    "#STEP: SAVING IMAGE-CAPTIONS IN TRAIN DATASET\n",
    "dev_dataset = {}\n",
    "for image_title, captions in tokens_dic.items():\n",
    "    if(image_title in dev and (image_title not in dev_dataset.keys())):\n",
    "        dev_dataset[image_title] = list()\n",
    "        for caption in captions:\n",
    "            refined_caption = \"startseq \" + caption + \" endseq\"\n",
    "            dev_dataset[image_title].append(refined_caption)\n",
    "#NOTE: SIZE OF DEV DATASET IS 1000\n",
    "\n",
    "\n",
    "#LOADING TESTING SET\n",
    "\n",
    "#STEP: EXTRACTING DATA\n",
    "filepath = \"../../../Downloads/Flickr8k/Flickr8k_text/Flickr_8k.testImages.txt\"\n",
    "file = open(filepath, \"r\")\n",
    "content = file.read()\n",
    "file.close()\n",
    "lines = content.split('\\n')\n",
    "\n",
    "#STEP: SAVING DATA IN A LIST\n",
    "test = []\n",
    "for line in lines:\n",
    "    [image_title, stuff] =  line.split('.')\n",
    "    test.append(image_title)\n",
    "#NOTE: SIZE OF TEST LIST IS 1000\n",
    "\n",
    "#STEP: SAVING IMAGE-CAPTIONS IN TRAIN DATASET\n",
    "test_dataset = {}\n",
    "for image_title, captions in tokens_dic.items():\n",
    "    if(image_title in test and (image_title not in test_dataset.keys())):\n",
    "        test_dataset[image_title] = list()\n",
    "        for caption in captions:\n",
    "            refined_caption = \"startseq \" + caption + \" endseq\"\n",
    "            test_dataset[image_title].append(refined_caption)\n",
    "#NOTE: SIZE OF TEST DATASET IS 1000\n",
    "\n",
    "\n",
    "#CONSTRUCTING VOCABULARY FROM CAPTIONS\n",
    "vocabulary = set()\n",
    "for captions in tokens_dic.values():\n",
    "    for caption in captions:\n",
    "        for word in caption.split():\n",
    "            vocabulary.add(word)\n",
    "#NOTE: SIZE OF VOCABULARY BY NOT LETTING 1 LENGTH WORDS BE IN CAPTION IS 8763\n",
    "\n",
    "#CONSTRUCTING MOST PROBABLE VOCABULARY FROM ALL TRAIN WORDS\n",
    "word_count_threshold = 10\n",
    "all_train_words = []\n",
    "for captions in train_dataset.values():\n",
    "    for caption in captions:\n",
    "        words = caption.split()\n",
    "        for word in words:\n",
    "            all_train_words.append(word)\n",
    "\n",
    "counter = Counter(all_train_words)\n",
    "commons = counter.most_common()\n",
    "most_probable_vocabulary = set()\n",
    "for ele in commons:\n",
    "    if(ele[1]>=word_count_threshold):\n",
    "        most_probable_vocabulary.add(ele[0])\n",
    "vocabulary_size = len(most_probable_vocabulary)\n",
    "#NOTE: SIZE OF MOST PROBABLE VOCABULARY BY NOT LETTING 1 LENGTH WORDS BE IN CAPTION IS 1651\n",
    "\n",
    "\n",
    "#READING ENCODED TRAIN IMAGES, ENCODED DEV IMAGES AND ENCODED TEST IMAGES FROM PKL FILES\n",
    "encoded_train_images = {}\n",
    "encoded_dev_images = {}\n",
    "encoded_test_images = {}\n",
    "with open(\"encoded_train_images3.pkl\", \"rb\") as encoded_pickle:\n",
    "    encoded_train_images = load(encoded_pickle)\n",
    "    \n",
    "with open(\"encoded_test_images3.pkl\", \"rb\") as encoded_pickle:\n",
    "    encoded_test_images = load(encoded_pickle)\n",
    "    \n",
    "with open(\"encoded_dev_images3.pkl\", \"rb\") as encoded_pickle:\n",
    "    encoded_dev_images = load(encoded_pickle)\n",
    "\n",
    "\n",
    "def data_generator(descriptions, photos, wordtoix, max_length, num_photos_per_batch):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n=0\n",
    "    while 1:\n",
    "        for key, desc_list in descriptions.items():\n",
    "            n+=1\n",
    "            photo = photos[key]\n",
    "            for desc in desc_list:\n",
    "                seq = [wordtoix[word] for word in desc.split(' ') if word in wordtoix]\n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocabulary_size+1)[0]\n",
    "                    X1.append(photo)\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n==num_photos_per_batch:\n",
    "                yield [[array(X1), array(X2)], array(y)]\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n=0\n",
    "                \n",
    "                \n",
    "#USEFUL DICTIONARIES\n",
    "index_to_word = {}\n",
    "word_to_index = {}\n",
    "index = 1\n",
    "for word in most_probable_vocabulary:\n",
    "    index_to_word[index] = word\n",
    "    word_to_index[word] = index\n",
    "    index+=1\n",
    "\n",
    "\n",
    "#WORD EMBEDDINGS, MAPPING EVERY WORD OF OUR MOST PROBABALE VOCABULARY TO 200 DIMENSION VECTOR, FOR THAT WE WILL BE USING GLOVE\n",
    "embeddings = {}\n",
    "file = open(\"../../../Downloads/glove/glove.6B.200d.txt\", \"r\")\n",
    "content = file.read()\n",
    "file.close()\n",
    "lines = content.split('\\n')\n",
    "for line in lines:\n",
    "    word_and_vector = line.split()\n",
    "    word = word_and_vector[0]\n",
    "    vector = word_and_vector[1:]\n",
    "    vector = np.asarray(vector, dtype='float32')\n",
    "    embeddings[word] = vector\n",
    "    \n",
    "    \n",
    "#MAPPING MOST PROBABLE VOCABULARY TO VECTOR BY CREATING A DENSE MATRIX WITH ROW AS WORD AND COLUMNS ARE 200 DIMENSIONS OF VECTOR\n",
    "embedding_dim = 200\n",
    "embeddings_matrix = np.zeros((vocabulary_size+1, embedding_dim))\n",
    "for word, index in word_to_index.items():\n",
    "    vector = embeddings.get(word)\n",
    "    if(vector is not None):\n",
    "        embeddings_matrix[index]=vector\n",
    "#NOTE: DIMENSION OF EMBEDDINGS MATRIX IS (MOST PROBABLE VOCABULARY X 200), HERE (1951 X 200)\n",
    "#NOTE: 1ST ROW OF EMBEDDINGS MATRIX IS ALL ZEROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "<img src=\"files/images/model1_arch.png\">\n",
    "<img src=\"files/images/model_summary.png\">\n",
    "<img src=\"files/images/model_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model2_arch.png\">\n",
    "<img src=\"files/images/model2_summary.png\">\n",
    "<img src=\"files/images/model2_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model3_arch.png\">\n",
    "<img src=\"files/images/model3_summary.png\">\n",
    "<img src=\"files/images/model3_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model4_arch.png\">\n",
    "<img src=\"files/images/model4_summary.png\">\n",
    "<img src=\"files/images/model4_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model5_arch.png\">\n",
    "<img src=\"files/images/model5_summary.png\">\n",
    "<img src=\"files/images/model5_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model6_arch.png\">\n",
    "<img src=\"files/images/model6_summary.png\">\n",
    "<img src=\"files/images/model6_performance.png\">\n",
    "\n",
    "# model\n",
    "<img src=\"files/images/model7_arch.png\">\n",
    "<img src=\"files/images/model7_summary.png\">\n",
    "<img src=\"files/images/model7_performance.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1536)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 34, 200)      330400      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_dropout_3 (GaussianDro (None, 1536)         0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_dropout_4 (GaussianDro (None, 34, 200)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          393472      gaussian_dropout_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 256)          467968      gaussian_dropout_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256)          0           dense_4[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          65792       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1652)         424564      dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,682,196\n",
      "Trainable params: 1,682,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#SAME ARCHITECTURE AS MODEL\n",
    "input1 = Input(shape=(1536,))\n",
    "fe1 = GaussianDropout(0.5)(input1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "input2 = Input(shape=(max_caption_length,))\n",
    "se1 = Embedding(vocabulary_size+1, embedding_dim, mask_zero=True)(input2)\n",
    "se2 = GaussianDropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "\n",
    "output = Dense(vocabulary_size+1, activation='softmax')(decoder2)\n",
    "model8 = Model(inputs=[input1, input2], outputs=output, name=\"model8\")\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETTING ADDITIONAL PROPERTIES FOR EMBEDDING LAYER\n",
    "model8.layers[2].set_weights([embeddings_matrix])\n",
    "model8.layers[2].trainable = False\n",
    "\n",
    "model8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.9.3 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-623fc1b1b02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wandb/wandb_config.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, val)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0m__setattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wandb/wandb_config.py\u001b[0m in \u001b[0;36mpersist\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0mconf_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# we update the runs history._steps in extreme hack fashion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# TODO: this reserves a bigtime refactor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mnew_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnew_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_step\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36minit_run\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"upserting run before process can begin, waiting at most %d seconds\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTP_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0masync_upsert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInternalApi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTP_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_run_thread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masync_upsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_run_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 logger.error(\"Failed to connect to W&B servers after %i seconds.\\\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wandb/util.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "wandb.config.dropout = 0.5\n",
    "wandb.config.hidden_layer_size = 3\n",
    "wandb.config.epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS OF TRAINING SESSION 1\n",
    "#NOTE: DEFAULT LEARNING RATE OF KERAS MODEL IS 0.001\n",
    "epochs = 20\n",
    "batch_size = 3\n",
    "steps = len(train_dataset)//batch_size\n",
    "#NOTE: SIZE OF TRAIN DATASET IS 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING SESSION 1\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_dataset, encoded_train_images, word_to_index, max_caption_length, batch_size)\n",
    "    hist = model8.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    loss = hist.history['loss']\n",
    "    wandb.log({'epoch': i+1, 'loss': loss})\n",
    "model8.save('./model8_weights/model_' + str(0) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS OF TRAINING SESSION 2\n",
    "#NOTE: LEARNING RATE IS CHANGED TO 0.0003\n",
    "K.set_value(model8.optimizer.lr, 0.0003)\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "steps = len(train_dataset)//batch_size\n",
    "#NOTE: SIZE OF TRAIN DATASET IS 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING SESSION 2\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(train_dataset, encoded_train_images, word_to_index, max_caption_length, batch_size)\n",
    "    hist = model7.fit_generator(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "    loss = hist.history['loss']\n",
    "    wandb.log({'epoch': i+21, 'loss': loss})\n",
    "model7.save('./model7_weights/model_' + str(1) + '.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
